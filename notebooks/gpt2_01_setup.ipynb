{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU and set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set eos_token as pad_token for the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Load the model, set pad_token_id and move to device\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "\t\"gpt2\", \n",
    "\tpad_token_id=tokenizer.eos_token_id,\n",
    "\ttorch_dtype=torch.float16,\n",
    "\tdevice_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS token id: 50256\n",
      "EOS token: <|endoftext|>\n",
      "Pad token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "eos_tok = tokenizer.eos_token_id\n",
    "print(f\"EOS token id: {eos_tok}\")\n",
    "print(f\"EOS token: {tokenizer.decode(eos_tok)}\")\n",
    "print(f\"Pad token: {tokenizer.pad_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[15496,  2159],\n",
      "        [15496, 50256]]), 'attention_mask': tensor([[1, 1],\n",
      "        [1, 0]])}\n",
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer([\"Hello World\", \"Hello\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "print(batch)\n",
    "print(tokenizer.encode(\"<|endoftext|>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input\n",
    "prompt = \"The future of AI is\"\n",
    "\n",
    "# Tokenize the input and move to the device\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the output\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "\tmax_new_tokens=50, \n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 55])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the output\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of AI is in the hands of the next generation of AI.\n",
      "\n",
      "The future of AI is in the hands of the next generation of AI.\n",
      "\n",
      "The future of AI is in the hands of the next generation of AI.\n",
      "\n",
      "The future of AI\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
